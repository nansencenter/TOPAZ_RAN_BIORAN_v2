#!/bin/bash

# File: assimilate.sh
# Author : Pavel Sakov # Date: 11 January 2010
# Corrected by Jiping Xie # Date: 5 June 2019
#
# Description:
#   This is a top level script for data assimilation in TOPAZ4.
#   It uses the prior art from TOPAZ3 and tries to simplify that existing
#   workflow based on possibilities open by the latest EnKF code.
#
#   This procedure is supposed to be called from main.sh. Otherwise your
#   assimilation_specs.sh may be outdated. If ran as a standalone script, it
#   should be launched from the directory one level up from here.
#
# WARNING:
#   Do not edit this file. Specify your custom settings in
#   "assimilation_specs.in" instead.

set -e # exit on error
set -u # exit on unset variables
set -p # nothing is inherited from the shell
set -x

MONITORINTERVAL=10 # time interval for periodic checks on job status
MONITORINTERVAL2=30 # time interval for periodic checks on job status
LAUNCHINTERVAL=5 # time interval for launching parallel jobs
nre=0 # number of members reassembled

#
# 1. Read and report specifications for the assimilation
#
echo "1. Reading specifications and checking configuration:"
. ./assimilation_specs.sh
export ANALYSISDIR BINDIR RESULTSDIR JULDAY ENSSIZE NPROC FORECASTDIR BACKUPBUFDIR MODELDIR HYCOMPREFIX PREPOBSDIR OUTPUTDIR NESTINGDIR OBSDIR ROOTDIR

echo "   JULDAY = ${JULDAY}"

# clean up
#
rm -rf ${ANALYSISDIR} ${PREPOBSDIR}
mkdir ${ANALYSISDIR}

echo "   Data types:"
for datatype in $OBSTYPES
do
    echo "     $datatype"
done

echo "   Directories:"
./SCRIPTS/check_directories.sh

echo "   EnKF parameters:"
cat enkf.prm | awk '{print "     "$0}'

./SCRIPTS/check_files.sh


#
# 2. Prepare observations of each type
#
echo "2. Preparing observations:"
echo "   "`date`

# for each obs type dowbnload observations and run prep_obs
#
for obstype in ${OBSTYPES}
do
    echo "   $obstype:"
    echo ${PREPOBSDIR}/observations.uf.${obstype} 
    if [ -s ${PREPOBSDIR}/observations.uf.${obstype} ]; then
      rm ${PREPOBSDIR}/observations.uf.${obstype} 
    fi
    cd ${CWD}
    if [ ${OBSREADY} -eq 0 ]; then
      # to create the observations.uf
      ./SCRIPTS/${obstype}/get_obs.sh
      if [ -f "${PREPOBSDIR}/${obstype}.OK" ]
      then
  	./SCRIPTS/${obstype}/write_infile.sh
	cd ${PREPOBSDIR}
	ln -sf infile.data.${obstype} infile.data
    
	echo -n "     running prep_obs..."
	${BINDIR}/prep_obs 2>&1 > prepobs.log.${obstype}
	if [ $? -ne 0 ]
	    then
	    echo "ERROR: error running prepobs for $obstype"
	    exit 1
	fi
	mv observations.uf observations.uf.${obstype}
	logstr=`cat prepobs.log.${obstype} |grep observations |grep "\->" | awk '{print $1 " obs. -> " $4 " obs."}'`
	if [ -z "${logstr}" ]
	then
	    logstr=`cat prepobs.log.${obstype} |grep observations | grep variable | awk '{print $6" obs."}'`
	fi
	if [ -s "observations.uf.${obstype}" ]
	then
	    echo "OK (${logstr})"
	else
	    rm -f ${PREPOBSDIR}/${obstype}.OK
	    echo "     NO OBS"
	fi
      else
	echo "     NO OBS"
	touch ${PREPOBSDIR}/observations.uf.${obstype}
      fi
    else
      # to link the observations.uf
      echo "OBSDIR="${OBSDIR}
      if [ ${obstype}x = "IDRFT"x ]; then
        lday0=0
        for lday in `seq 1 5`; do
          Fnam=${OBSDIR}/${obstype}/obs_${obstype}${lday}_${JULDAY}
          if [ -s ${Fnam}.uf ]; then
            if [ ${lday0} -eq 0 ]; then
              touch ${PREPOBSDIR}/observations.uf.${obstype}
            fi
            cat ${Fnam}.uf >> ${PREPOBSDIR}/observations.uf.${obstype}
            let lday0=lday0+1
            ln -sf ${OBSDIR}/${obstype}/obs_DX${lday}_${JULDAY}.nc ${PREPOBSDIR}/observations-DX${lday}.nc
            ln -sf ${OBSDIR}/${obstype}/obs_DY${lday}_${JULDAY}.nc ${PREPOBSDIR}/observations-DY${lday}.nc
          fi
        done
        if [ ${lday0} -eq 0 ]; then
	  echo "     NO OBS"
	  touch ${PREPOBSDIR}/observations.uf.${obstype}
        else
          touch ${PREPOBSDIR}/${obstype}.OK
        fi
      elif [ ${obstype}x = "SKIM"x ]; then
        icheck=0
        for lday in `seq 1 6`; do
          let tmjdy=JULDAY-lday
          Fnam=${OBSDIR}/SKIM/obs_SKIM_${tmjdy}
          if [ -s ${Fnam}.nc -a -s ${Fnam}.uf ]; then
            cp -sf ${Fnam}.uf ${PREPOBSDIR}/observations.uf.${obstype}
            ln -sf ${Fnam}.nc ${PREPOBSDIR}/observations-${obstype}.nc
            touch ${PREPOBSDIR}/${obstype}.OK
            icheck=1
          fi
        done
        if [ ${icheck} -eq 0 ]; then
          echo "     NO OBS from " ${obstype}
	  touch ${PREPOBSDIR}/observations.uf.${obstype}
        fi
      else
         # searching once time during the assimilation time window
         AWtime=3
         if [ ${obstype}x = "HICE"x ]; then
            AWtime=6
         fi
         icheck=0
         lday=1
         while [ ${lday} -le ${AWtime} ]; do
            let tmjdy=JULDAY-lday
            Fnam=${OBSDIR}/${obstype}/obs_${obstype}_${tmjdy}
            echo ${Fnam}
            if [ -s ${Fnam}.nc -a -s ${Fnam}.uf -a ${icheck} -eq 0 ]; then
              cp -sf ${Fnam}.uf ${PREPOBSDIR}/observations.uf.${obstype}
              ln -sf ${Fnam}.nc ${PREPOBSDIR}/observations-${obstype}.nc
              touch ${PREPOBSDIR}/${obstype}.OK
              icheck=1
            fi
            let lday=lday+1
         done
         if [ ${icheck} -eq 0 ]; then
	   echo "     NO OBS from " ${obstype}
	   touch ${PREPOBSDIR}/observations.uf.${obstype}
         fi
      fi
    fi
done


if stat -t ${PREPOBSDIR}/*.OK > /dev/null 2>&1
then
    cd ${PREPOBSDIR}
    rm -f observations.uf
    touch observations.uf
    for obstype in $OBSTYPES
    do
        cat observations.uf.${obstype} >> observations.uf
    done
    cp observations* ${ANALYSISDIR}
fi

cd "${CWD}"
echo CWD= ${CWD}


#
# 3. Link the inputs
#
echo "3. Linking the forecast and observations to the analysis directory:"
./SCRIPTS/link_inputs.sh


#
# 4. calculate ensemble mean forecast and save it along with the first
#    member in the results directory (in the background)
#
echo "4. Launching sr_preprocess.sh"
echo "   (converts the forecast enemble to NetCDF and calculates forecast ensemble mean)"
echo "   "`date`

cd "${ANALYSISDIR}"
NN=100  # batch size

(( NPRE = ($ENSSIZE - 1) / $NN + 1 ))
for (( proc = 0; proc < $NPRE; ++proc ))
do
    (( ESTART = $proc * $NN + 1 ))
    (( EEND = ($proc + 1) * $NN ))
    if (( $EEND > $ENSSIZE ))
    then
	EEND=$ENSSIZE
    fi
    cat ${CWD}/SCRIPTS/sr_preprocess.in |\
	sed "s/ESTART/${ESTART}/" |\
	sed "s/EEND/${EEND}/" |\
	sed "s#EXVAR0#${BINDIR}#" |\
	sed "s#EXVAR1#${ANALYSISDIR}#" |\
	sed "s/EXVAR2/${ENSSIZE}/" |\
	sed "s#EXVAR_1#${RESULTSDIR}#" |\
	sed "s/EXVAR_2/${JULDAY}/" |\
	sed "s/en_pre/en_pre${proc}/g"\
	> ${ANALYSISDIR}/sr_preprocess${proc}.sh
    jobid_pre[$proc]=`sbatch ${ANALYSISDIR}/sr_preprocess${proc}.sh 2>/dev/null| tail -l | awk '{print $4}'`
    echo "   ${proc}: Submitted batch job ${jobid_pre[$proc]}: preprocess members ${ESTART} - ${EEND}"
    sleep ${LAUNCHINTERVAL}
done

echo -n "   now waiting for all preprocessing jobs to finish:"
finished=0
while (( ! finished ))
do
    finished=1
    for (( proc = 0; proc < ${NPRE}; ++proc ))
    do
        if [ -z "${jobid_pre[$proc]}" ]
	then
	    continue
	fi
	answer=`squeue --job ${jobid_pre[$proc]} 2>/dev/null | tail -1 | awk '{print $5}'`
	sleep ${MONITORINTERVAL}
        #echo ${answer}
	if [ -z "${answer}" -o "${answer}" == "ST" ]
	    then
	    #jobid_pre[$proc]=
	    echo -n "."${proc}
	else
	    echo -n "."
	    finished=0
	    sleep ${MONITORINTERVAL}
	fi
    done
done
echo " done: " `date`

#
#  echo "calculate the model date for the feedback restart files"
#
(( juldaynow = $JULDAY + 1 ))
yearnow=`jultodate $juldaynow 1950 1 1 | cut -c1-4`

Jday=`datetojul $yearnow 1 1 1950 1 1`
if [ ${juldaynow} -eq ${Jday} ]; then
   daynow=0
else
   let daynow=${juldaynow}-${Jday}
fi
daynow=`printf "%03d" $daynow`


if [ -f "${PREPOBSDIR}/observations.uf" ]
then

#
# 5. Run EnKF
#
    echo "5. Running EnKF:"
    echo "   "`date`

    cd ${ANALYSISDIR}
    echo ${ANALYSISDIR}
    cat ${CWD}/SCRIPTS/sr_enkf.in |\
	sed "s#EXVAR0#${BINDIR}#" |\
	sed "s#EXVAR1#${ANALYSISDIR}#" |\
	sed "s/EXVAR2/${ENSSIZE}/" |\
	sed "s/EXVAR3/${NPROC}/" >  ${ANALYSISDIR}/sr_enkf.sh
# run EnKF
#
    jobid_enkf=`sbatch ${ANALYSISDIR}/sr_enkf.sh 2>/dev/null | tail -l | awk '{print $4}'`
    #jobid_enkf=`sbatch sr_enkf.sh 2>/dev/null| tail -l | awk '{print $4}'`
    sleep ${MONITORINTERVAL}
    echo "submit  ${jobid_enkf}"
# wait until EnKF finishes
#
    answer=`squeue --job ${jobid_enkf} 2>/dev/null | tail -1 | awk '{print $5}'`
    while [ -n "${answer}" -a "${answer}" != "ST" ]
    do
	echo -n "."
	sleep ${MONITORINTERVAL}
        answer=`squeue --job ${jobid_enkf} 2>/dev/null | tail -1 | awk '{print $5}'`
	if [ -r break.out ]; then 
           answer="C"
           echo "exit!"
           exit
	fi
    done
    status=`cat ${ANALYSISDIR}/enkf_0.out | grep EnKF: | grep -c Finished`
    if (( ${status} != ${NPROC} ))
    then
	echo
	echo "ERROR: EnKF has not finished"
	echo
	exit 1
    else
	echo "   EnKF finished"
    fi

#
# 6. Postprocess
#
    echo "6. Postprocess:"
    echo "   (assembles, checks, fixes and converts to NetCDF)"
    echo "   "`date`
    cd ${ANALYSISDIR}
    #NN=6 # batch size
    (( NPOST = ($ENSSIZE - 1) / $NN + 1 ))
    for (( proc = 0; proc < ${NPOST}; ++proc ))
    do
        (( ESTART = $proc * $NN + 1 ))
	(( EEND = ($proc + 1) * $NN ))
	if (( $EEND > $ENSSIZE ))
	then
	    EEND=$ENSSIZE
	fi
# write script on Fram

    cat ${CWD}/SCRIPTS/sr_postprocess.in |\
	sed "s/ESTART/${ESTART}/" |\
	sed "s/EEND/${EEND}/" |\
	sed "s#EXVAR0#${BINDIR}#" |\
	sed "s#EXVAR1#${ANALYSISDIR}#" |\
	sed "s/EXVAR2/${ENSSIZE}/" |\
	sed "s/EXVAR3/${NPROC}/" |\
        sed "s/EXVAR4/${JULDAY}/" |\
	sed "s/EXVAR_1/${daynow}/" |\
	sed "s#EXVAR_2#${RESULTSDIR}#" |\
	sed "s/en_post/en_post${proc}/g"\
	> ${ANALYSISDIR}/sr_postprocess${proc}.sh

        jobid_post[$proc]=`sbatch ${ANALYSISDIR}/sr_postprocess${proc}.sh 2>/dev/null| tail -l | awk '{print $4}'`
        echo "   ${proc}: Submitted batch job ${jobid_post[$proc]}: postprocess members ${ESTART} - ${EEND}"
        sleep ${LAUNCHINTERVAL}
    done

# wait until postprocessing finishes
#

    echo -n "   now waiting for postprocessing jobs to finish:"
    finished=0
    while (( ! finished ))
    do
        finished=1
	for (( proc = 0; proc < ${NPOST}; ++proc ))
	do
	    if [ -z "${jobid_post[$proc]}" ]
	    then
		continue
	    fi
	    answer=`squeue --job ${jobid_post[$proc]} 2>/dev/null | tail -1 | awk '{print $5}'`
       	    if [ -z "${answer}" -o "${answer}" == "ST" ]
	        then
	        jobid_post[$proc]=
	        echo -n ".. post .. ${proc}"
	    else
	        echo -n "."
	        finished=0
	        sleep ${MONITORINTERVAL}
            fi
	done
    done
    echo " postprocess done"


# 7. Check the analysis
#
    chmod -R a+r+X ${ANALYSISDIR}
    echo "   postprocessing finished OK"
    echo "7. Cleaning up:"
    echo "   "`date`
    echo "   copying/moving forecast and analysis..."
    cd ${ANALYSISDIR}

    # write script on Fram
    cat ${CWD}/SCRIPTS/sr_cleanup.in |\
       sed "s/EXVAR1/${ENSSIZE}/" |\
       sed "s/EXVAR2/${JULDAY}/" |\
       sed "s#EXDIR1#${ANALYSISDIR}#" |\
       sed "s#EXDIR2#${RESULTSDIR}#" |\
       sed "s#EXDIR3#${MODELDIR}#" |\
       sed "s#EXDIR4#${FORECASTDIR}#" |\
       sed "s#EXDIR5#${BACKUPBUFDIR}#" |\
       sed "s#EXDIR6#${OUTPUTDIR}#" |\
       sed "s/MODNAM/TP5/g"\
           > ${ANALYSISDIR}/sr_cleanup.sh

    jobid_clean=`sbatch ${ANALYSISDIR}/sr_cleanup.sh 2>/dev/null| tail -l | awk '{print $4}'`
    sleep ${MONITORINTERVAL}
    echo "   ${jobid_clean}"
    echo -n "   waiting until ${jobid_clean} finish:"

    # wait until all copying finishes
    #
    answer=`squeue --job ${jobid_clean} 2>/dev/null | tail -1 | awk '{print $5}'`
    while [ -n "${answer}" -a "${answer}" != "ST" ]; do
       echo -n ".. cleanup .."
       sleep ${MONITORINTERVAL}
       answer=`squeue --job ${jobid_clean} 2>/dev/null | tail -1 | awk '{print $5}'`
    done

    echo "   "`date`
    echo -n "   launching some background backup jobs:"

    cd ${ANALYSISDIR}
#    # write script on Fram
#    cat ${CWD}/SCRIPTS/sr_cleanup2.in |\
#        sed "s/EXVAR1/${ENSSIZE}/" |\
#        sed "s/EXVAR2/${JULDAY}/" |\
#        sed "s#EXDIR0#${ROOTDIR}#" |\
#        sed "s#EXDIR1#${ANALYSISDIR}#" |\
#        sed "s#EXDIR2#${RESULTSDIR}#" |\
#        sed "s#EXDIR3#${MODELDIR}#" |\
#        sed "s#EXDIR4#${OUTPUTDIR}#" |\
#        sed "s#EXDIR5#${BACKUPBUFDIR}#" |\
#        sed "s#EXDIR6#${OBSDIR}#" |\
#        sed "s/EXVAR2/${JULDAY}/g"\
#          > ${ANALYSISDIR}/sr_cleanup2.sh
#    
    # switch on the backup by the compressed files 
    #jobid_clean2=`sbatch ${ANALYSISDIR}/sr_cleanup2.sh 2>/dev/null| tail -l | awk '{print $4}'`

else
    jobid_amean=NONE
fi # -f observations.uf


